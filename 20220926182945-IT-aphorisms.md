# IT Aphorisms

1. Failure to scope your project adequately will result in failure to deliver said project. Do you even know what your project is, if you haven't scoped it? The scope _is_ the project. 
2. Projects must be rooted in _reality_. This means first and foremost obeying the physical laws of the universe. This includes the laws of thermodynamics and therefore no project is immune to _entropy_. And no, if bugs could be predicted and pre-empted, that would mean time-travel is possible and this breaks all the known laws of the universe.
3. Something must serve as the single source of truth. Always. It doesn't necessarily matter what it is, but it must exist.
4. If it's not a ticket, it's not getting done.
5. Time spent in meetings is inversely correlated with productivity. 
6. Communication overhead grows exponentially in relation to the number of people on a team. There's a point beyond which no useful production occurs beyond maintaining the status quo. 
7. Knowledge work is non-linear and hours in doesn't equal hours out in terms of production. 
8. Productivity obey's the _pareto principle_ in that 80% of the work is being done by 20% of the workers. This an immutable law of the universe. 
9. If it's not documented somewhere, "science" must be conducted to understand the system through rigorous positing of hypothesis and developing models (i.e. theories) via testing, and observation. Only once concrete evidence is obtained through observational tools and a useful _model_ developed (i.e. theory) can the system be reliably fixed when it inevitably breaks. This is an arduous and time-consuming process. It's often many orders of magnitude simpler to rebuild the system, documenting as you go, than it is to try to understand an undocumented system that already exists. This is the origins of most "technical debt."
10. Lack of documentation is probably the single greatest source of "technical debt" beyond poor design or development choices.
11. Documentation is a moral obligation to your fellow IT professionals. It's unequivocally ethically "good" to write documentation and worse than mere laziness but for all intents and purposes "evil" to fail to produce adequate documentation alongside delivery of any sort of developed system, body of work, coded project, or other necessarily complex system. 
12. Visual aids such as lovingly crafted network diagrams are a love-letter to future sysadmins. This is the art of documentation. It's intrinsically good to produce this form of documentation even if nobody ever see's it other than you. 
13. Failure to document is failure to embue your thing with enough evolutionary relevance to survive the first iteration of said thing. It will cease to exist beyond it's first iteration since it will be too difficult to understand and it will instead be replaced by a newer heartier version of the thing. The only exceptions are a thing that's so business useful it's worth infusing inordinate amounts of resources (money) to "life-support" said thing. 
14. Context is everything. Problems don't exist outside of the context they live in. Failure to provide context is failure to provide a problem rooted in reality. Problems not rooted in reality are fictitious and not real problems. See laws of physics above.  
15. Computers do everything you tell them to, nothing more nothing less. 
16. Complexity is the devil. 
17. The simplest solution is almost always the best solution. The absolute simplest solution is no solution at all.  For this reason, it's worth putting serious thought into if your thing should exist at all. After all, existence creates problems that then need to be solved. Entropy dictates this. 
18. You can't solve the problem before defining the problem in concrete terms. If you can't define the problem in concrete terms you don't understand enough about the system to define it. If you don't understand the system, either read the docs or if those don't exist, do more "science" (see above) to understand the problem space. Apprenticeship from a wizard is the only "short-cut" to RTFM and/or doing "science". But it's not a substitute for those two things and should be used sparingly. 
19. Sometimes if you try to formulate your problem in such a way that you can describe it to someone else you'll solve your own problem. This is because you've only now "defined your problem in concrete terms" (see above). Reaching out to others and formulating your problem is a valid problem solving method. 
20. If don't truly "know" something until you can describe it in a way that a 5 year old can understand. 
21. You don't really understand something until you can build something with it. 
22. Attitude is more than half the battle. 
23. Some problems are in a special class of problems analagous to quantum particles in that observation of the problem affects the problem itself. You can know either a particle's position or velocity, but not both. Observation of the problem will change the nature of the problem. The good news is the solution is usually _static_ even if observations are subject to change. The wise sysadmin knows this, and is thus unsurprised when different observational tools produce different results for the same problems. Only through testing and continued observation can the problem space be narrowed through iterative deduction towards a solution "limit." Using the calculus analogy most problems _converge_, but some classes of problems (i.e. impossible problems) _diverge_. Experience is required to identify _divergent_ probems, and mastery required to be able to set aside such problems. 
24. In a similar fashion, some problems don't exist until they are observed. These are the "if a tree falls in the forest but no one is there to hear it, does it make a sound?" class of problems. For this reason it's important to make sure that monitoring and alerting tools are calibrated effectively such that you're not creating a limitless supply of "problems" for yourself and your team. Problems are literally _infinite_ if you look hard enough, but the solution space is for all practical purposes _finite._
25. _Don't go looking for problems._
26. Triaging problems is essential. Some problems are not really problems in that the system is stable enough to survive uncritical classes of problems, in many cases indefinitely. Given this, are they really problems? Other problems kill the host and should be treated with utmost urgency. Most problems are somewhere in-between these two extremes.  Triage problems ruthlessly or forever be chasing the receding horizon that is your problem set. 
27. Performance optimization is a class of problems that may be both uncritical or critical depending on the context. At some point performance optimization becomes "yak shaving" and is best avoided. 
28. Backups are only as valuable as the regular testing and documentation of your _disaster recovery_ solution. Without testing, your backup solution is little more than worthless. 
29. There's usually a "right" way to do something, or at least a "more right" way to do something. It's many orders of magnitude easier and faster to do something right the first time than it is to try to fix it later (if it's even possible to fix it later). Alongside lack of documentation this may be the 2nd most abundant reason for "technical debt".
30. Customers are often wrong and if not handled carefully may introduce more technical debt than can be reasonably managed by the IT resources available. If left completely unchecked this could easily result in a runaway problem cascade that can't be resolved with the IT-resources available in the known universe.
31. Educating the customer must be achieved "diplomatically" or the IT professional may find themselves saddled with "financial" problems instead of our preferred "technical" ones. 
32. There exists space in a venn-diagram of customer "asks" and "solvable problems" that's neither the "most right" solution or impossible. This is a balance that must be delicately maintained. (see runaway problem cascade above)
33. Solve _root issues_ not _symptoms_. Solving symptoms is little better than a "bandaid" in most cases, and in some cases creates more "problems" to be solved. The only right solution is solving the root issue. QED
34. HA is only as good as it's implementation and in practice only as good as the sysadmins maintaining it. Overly complex or difficult to maintain HA systems may in fact be less reliable and result in more downtime in practice than a single monolithic system. Think carefully before introducing this level of complexity to your system. HA is by no means a silver-bullet and should be implemented sparingly. An undocumented HA solution may as well not exist. Anybody who asks for HA as a solution to the class of "all problems resulting in downtime" doesn't truly understand HA. (See educating the customer above)
35. DR tests don't always go according to plan, that's why they're called DR "tests". 
36. DNS is almost always the issue. 
37. Most developers and software admins don't truly understand DNS. 
38. Any developer who understands DNS and networking is actually "DevOps" despite what their title might say. 
39. You can't "can haz am developer/sysadmin/devops/engineer now" in a 12-week bootcamp, despite marketing to the contrary.
40. There's no short-cuts to "sysadmin/developer/devops." Most of us started at "tier 1" of something and if we didn't we're lying about the experience we had going into our "entry level" _jr_ (or better) role (or we knew somebody, i.e. nepotism). 
41. Formal education in computer science is weakly correlated with future success in the field, if it's correlated at all. It could be argued that IT is really more of an "apprenticeship" and for most practical purposes it's best approached with "hands-on" learning. 
42. IT certificates are little better than bullet points on a resume that get your foot in the door with recruiters. Most IT professionals could care less and the proof is the the pudding so-to-speak. It's possible to study for the test and not really understand a lot of what you "learned." It's even more common to cram for the test and forget 90% of what you learned.The only exception is skills learned in a lab that closely approximates real-life scenarios.  We only care about the skills you can demonstrate and being able to solve real problems in the field. Willingness to learn, attitude, and analytical thinking skills are far more important than any certification. It's your _approach_ to a problem that's unfamiliar to you that's much more important than whether or not you get the right answer at least as far as interviewing is concerned. 
42. Leet-code test type interviews are mostly useless at determining performance. Much like SAT and ACT testing they're weakly correlated (if at all correlated) with future success in the field. 
43. Portfolio projects are a much better indicator of true skills and knowledge. 